{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b567ef04-3f1f-4fbd-8f51-d6ca7a79b12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial keystroke Rows: 19996\n",
      "keystroke Rows after NaN drop: 19996\n",
      "\n",
      "Creating dataset for keystroke_session_hijacking_abrupt\n",
      "Evaluating models for keystroke_session_hijacking_abrupt\n",
      "Training and evaluating Random Forest...\n",
      "Failed to evaluate Random Forest: list index out of range\n",
      "Training and evaluating SVM...\n",
      "Failed to evaluate SVM: list index out of range\n",
      "Training and evaluating KNN...\n",
      "Failed to evaluate KNN: list index out of range\n",
      "Training and evaluating XGBoost...\n",
      "Failed to evaluate XGBoost: list index out of range\n",
      "Training and evaluating Voting...\n",
      "Failed to evaluate Voting: list index out of range\n",
      "Training and evaluating Snapshot RF...\n",
      "Failed to evaluate Snapshot RF: list index out of range\n",
      "Training and evaluating Hoeffding Tree...\n",
      "Failed to evaluate Hoeffding Tree: list index out of range\n",
      "Training and evaluating HAT...\n",
      "Failed to evaluate HAT: list index out of range\n",
      "Training and evaluating Leveraging Bagging...\n",
      "Failed to evaluate Leveraging Bagging: list index out of range\n",
      "Training and evaluating Online Boosting...\n",
      "Failed to evaluate Online Boosting: list index out of range\n",
      "Training and evaluating OKD...\n",
      "Failed to evaluate OKD: list index out of range\n",
      "Training and evaluating SRP...\n",
      "Failed to evaluate SRP: list index out of range\n",
      "\n",
      "Results for keystroke_session_hijacking_abrupt:\n",
      "Error evaluating keystroke dataset: \"None of [Index(['Model', 'Accuracy_Mean', 'TPR_Mean', 'FRR_Mean', 'DDA_Mean', 'AL_Mean',\\n       'Delta_Acc_vs_Static', 'p_value_vs_Static'],\\n      dtype='object')] are in the [columns]\"\n",
      "\n",
      "Creating dataset for keystroke_mitm_recurring\n",
      "Evaluating models for keystroke_mitm_recurring\n",
      "Training and evaluating Random Forest...\n",
      "Failed to evaluate Random Forest: list index out of range\n",
      "Training and evaluating SVM...\n",
      "Failed to evaluate SVM: list index out of range\n",
      "Training and evaluating KNN...\n",
      "Failed to evaluate KNN: list index out of range\n",
      "Training and evaluating XGBoost...\n",
      "Failed to evaluate XGBoost: list index out of range\n",
      "Training and evaluating Voting...\n",
      "Failed to evaluate Voting: list index out of range\n",
      "Training and evaluating Snapshot RF...\n",
      "Failed to evaluate Snapshot RF: list index out of range\n",
      "Training and evaluating Hoeffding Tree...\n",
      "Failed to evaluate Hoeffding Tree: list index out of range\n",
      "Training and evaluating HAT...\n",
      "Failed to evaluate HAT: list index out of range\n",
      "Training and evaluating Leveraging Bagging...\n",
      "Failed to evaluate Leveraging Bagging: list index out of range\n",
      "Training and evaluating Online Boosting...\n",
      "Failed to evaluate Online Boosting: list index out of range\n",
      "Training and evaluating OKD...\n",
      "Failed to evaluate OKD: list index out of range\n",
      "Training and evaluating SRP...\n",
      "Failed to evaluate SRP: list index out of range\n",
      "\n",
      "Results for keystroke_mitm_recurring:\n",
      "Error evaluating keystroke dataset: \"None of [Index(['Model', 'Accuracy_Mean', 'TPR_Mean', 'FRR_Mean', 'DDA_Mean', 'AL_Mean',\\n       'Delta_Acc_vs_Static', 'p_value_vs_Static'],\\n      dtype='object')] are in the [columns]\"\n",
      "\n",
      "Creating dataset for keystroke_card_skimming_abrupt\n",
      "Evaluating models for keystroke_card_skimming_abrupt\n",
      "Training and evaluating Random Forest...\n",
      "Failed to evaluate Random Forest: list index out of range\n",
      "Training and evaluating SVM...\n",
      "Failed to evaluate SVM: list index out of range\n",
      "Training and evaluating KNN...\n",
      "Failed to evaluate KNN: list index out of range\n",
      "Training and evaluating XGBoost...\n",
      "Failed to evaluate XGBoost: list index out of range\n",
      "Training and evaluating Voting...\n",
      "Failed to evaluate Voting: list index out of range\n",
      "Training and evaluating Snapshot RF...\n",
      "Failed to evaluate Snapshot RF: list index out of range\n",
      "Training and evaluating Hoeffding Tree...\n",
      "Failed to evaluate Hoeffding Tree: list index out of range\n",
      "Training and evaluating HAT...\n",
      "Failed to evaluate HAT: list index out of range\n",
      "Training and evaluating Leveraging Bagging...\n",
      "Failed to evaluate Leveraging Bagging: list index out of range\n",
      "Training and evaluating Online Boosting...\n",
      "Failed to evaluate Online Boosting: list index out of range\n",
      "Training and evaluating OKD...\n",
      "Failed to evaluate OKD: list index out of range\n",
      "Training and evaluating SRP...\n",
      "Failed to evaluate SRP: list index out of range\n",
      "\n",
      "Results for keystroke_card_skimming_abrupt:\n",
      "Error evaluating keystroke dataset: \"None of [Index(['Model', 'Accuracy_Mean', 'TPR_Mean', 'FRR_Mean', 'DDA_Mean', 'AL_Mean',\\n       'Delta_Acc_vs_Static', 'p_value_vs_Static'],\\n      dtype='object')] are in the [columns]\"\n",
      "\n",
      "Creating dataset for keystroke_phishing_gradual\n",
      "Evaluating models for keystroke_phishing_gradual\n",
      "Training and evaluating Random Forest...\n",
      "Failed to evaluate Random Forest: list index out of range\n",
      "Training and evaluating SVM...\n",
      "Failed to evaluate SVM: list index out of range\n",
      "Training and evaluating KNN...\n",
      "Failed to evaluate KNN: list index out of range\n",
      "Training and evaluating XGBoost...\n",
      "Failed to evaluate XGBoost: list index out of range\n",
      "Training and evaluating Voting...\n",
      "Failed to evaluate Voting: list index out of range\n",
      "Training and evaluating Snapshot RF...\n",
      "Failed to evaluate Snapshot RF: list index out of range\n",
      "Training and evaluating Hoeffding Tree...\n",
      "Failed to evaluate Hoeffding Tree: list index out of range\n",
      "Training and evaluating HAT...\n",
      "Failed to evaluate HAT: list index out of range\n",
      "Training and evaluating Leveraging Bagging...\n",
      "Failed to evaluate Leveraging Bagging: list index out of range\n",
      "Training and evaluating Online Boosting...\n",
      "Failed to evaluate Online Boosting: list index out of range\n",
      "Training and evaluating OKD...\n",
      "Failed to evaluate OKD: list index out of range\n",
      "Training and evaluating SRP...\n",
      "Failed to evaluate SRP: list index out of range\n",
      "\n",
      "Results for keystroke_phishing_gradual:\n",
      "Error evaluating keystroke dataset: \"None of [Index(['Model', 'Accuracy_Mean', 'TPR_Mean', 'FRR_Mean', 'DDA_Mean', 'AL_Mean',\\n       'Delta_Acc_vs_Static', 'p_value_vs_Static'],\\n      dtype='object')] are in the [columns]\"\n",
      "\n",
      "Creating dataset for keystroke_identity_theft_incremental\n",
      "Evaluating models for keystroke_identity_theft_incremental\n",
      "Training and evaluating Random Forest...\n",
      "Failed to evaluate Random Forest: list index out of range\n",
      "Training and evaluating SVM...\n",
      "Failed to evaluate SVM: list index out of range\n",
      "Training and evaluating KNN...\n",
      "Failed to evaluate KNN: list index out of range\n",
      "Training and evaluating XGBoost...\n",
      "Failed to evaluate XGBoost: list index out of range\n",
      "Training and evaluating Voting...\n",
      "Failed to evaluate Voting: list index out of range\n",
      "Training and evaluating Snapshot RF...\n",
      "Failed to evaluate Snapshot RF: list index out of range\n",
      "Training and evaluating Hoeffding Tree...\n",
      "Failed to evaluate Hoeffding Tree: list index out of range\n",
      "Training and evaluating HAT...\n",
      "Failed to evaluate HAT: list index out of range\n",
      "Training and evaluating Leveraging Bagging...\n",
      "Failed to evaluate Leveraging Bagging: list index out of range\n",
      "Training and evaluating Online Boosting...\n",
      "Failed to evaluate Online Boosting: list index out of range\n",
      "Training and evaluating OKD...\n",
      "Failed to evaluate OKD: list index out of range\n",
      "Training and evaluating SRP...\n",
      "Failed to evaluate SRP: list index out of range\n",
      "\n",
      "Results for keystroke_identity_theft_incremental:\n",
      "Error evaluating keystroke dataset: \"None of [Index(['Model', 'Accuracy_Mean', 'TPR_Mean', 'FRR_Mean', 'DDA_Mean', 'AL_Mean',\\n       'Delta_Acc_vs_Static', 'p_value_vs_Static'],\\n      dtype='object')] are in the [columns]\"\n",
      "Initial mouse Rows: 252397\n",
      "mouse Rows after NaN drop: 252397\n",
      "\n",
      "Creating dataset for mouse_session_hijacking_abrupt\n",
      "Evaluating models for mouse_session_hijacking_abrupt\n",
      "Training and evaluating Random Forest...\n",
      "Failed to evaluate Random Forest: list index out of range\n",
      "Training and evaluating SVM...\n",
      "Failed to evaluate SVM: list index out of range\n",
      "Training and evaluating KNN...\n",
      "Failed to evaluate KNN: list index out of range\n",
      "Training and evaluating XGBoost...\n",
      "Failed to evaluate XGBoost: list index out of range\n",
      "Training and evaluating Voting...\n",
      "Failed to evaluate Voting: list index out of range\n",
      "Training and evaluating Snapshot RF...\n",
      "Failed to evaluate Snapshot RF: list index out of range\n",
      "Training and evaluating Hoeffding Tree...\n",
      "Failed to evaluate Hoeffding Tree: list index out of range\n",
      "Training and evaluating HAT...\n",
      "Failed to evaluate HAT: list index out of range\n",
      "Training and evaluating Leveraging Bagging...\n",
      "Failed to evaluate Leveraging Bagging: list index out of range\n",
      "Training and evaluating Online Boosting...\n",
      "Failed to evaluate Online Boosting: list index out of range\n",
      "Training and evaluating OKD...\n",
      "Failed to evaluate OKD: list index out of range\n",
      "Training and evaluating SRP...\n",
      "Failed to evaluate SRP: list index out of range\n",
      "\n",
      "Results for mouse_session_hijacking_abrupt:\n",
      "Error evaluating mouse dataset: \"None of [Index(['Model', 'Accuracy_Mean', 'TPR_Mean', 'FRR_Mean', 'DDA_Mean', 'AL_Mean',\\n       'Delta_Acc_vs_Static', 'p_value_vs_Static'],\\n      dtype='object')] are in the [columns]\"\n",
      "\n",
      "Creating dataset for mouse_mitm_recurring\n",
      "Evaluating models for mouse_mitm_recurring\n",
      "Training and evaluating Random Forest...\n",
      "Failed to evaluate Random Forest: list index out of range\n",
      "Training and evaluating SVM...\n",
      "Failed to evaluate SVM: list index out of range\n",
      "Training and evaluating KNN...\n",
      "Failed to evaluate KNN: list index out of range\n",
      "Training and evaluating XGBoost...\n",
      "Failed to evaluate XGBoost: list index out of range\n",
      "Training and evaluating Voting...\n",
      "Failed to evaluate Voting: list index out of range\n",
      "Training and evaluating Snapshot RF...\n",
      "Failed to evaluate Snapshot RF: list index out of range\n",
      "Training and evaluating Hoeffding Tree...\n",
      "Failed to evaluate Hoeffding Tree: list index out of range\n",
      "Training and evaluating HAT...\n",
      "Failed to evaluate HAT: list index out of range\n",
      "Training and evaluating Leveraging Bagging...\n",
      "Failed to evaluate Leveraging Bagging: list index out of range\n",
      "Training and evaluating Online Boosting...\n",
      "Failed to evaluate Online Boosting: list index out of range\n",
      "Training and evaluating OKD...\n",
      "Failed to evaluate OKD: list index out of range\n",
      "Training and evaluating SRP...\n",
      "Failed to evaluate SRP: list index out of range\n",
      "\n",
      "Results for mouse_mitm_recurring:\n",
      "Error evaluating mouse dataset: \"None of [Index(['Model', 'Accuracy_Mean', 'TPR_Mean', 'FRR_Mean', 'DDA_Mean', 'AL_Mean',\\n       'Delta_Acc_vs_Static', 'p_value_vs_Static'],\\n      dtype='object')] are in the [columns]\"\n",
      "\n",
      "Creating dataset for mouse_card_skimming_abrupt\n",
      "Evaluating models for mouse_card_skimming_abrupt\n",
      "Training and evaluating Random Forest...\n",
      "Failed to evaluate Random Forest: list index out of range\n",
      "Training and evaluating SVM...\n",
      "Failed to evaluate SVM: list index out of range\n",
      "Training and evaluating KNN...\n",
      "Failed to evaluate KNN: list index out of range\n",
      "Training and evaluating XGBoost...\n",
      "Failed to evaluate XGBoost: list index out of range\n",
      "Training and evaluating Voting...\n",
      "Failed to evaluate Voting: list index out of range\n",
      "Training and evaluating Snapshot RF...\n",
      "Failed to evaluate Snapshot RF: list index out of range\n",
      "Training and evaluating Hoeffding Tree...\n",
      "Failed to evaluate Hoeffding Tree: list index out of range\n",
      "Training and evaluating HAT...\n",
      "Failed to evaluate HAT: list index out of range\n",
      "Training and evaluating Leveraging Bagging...\n",
      "Failed to evaluate Leveraging Bagging: list index out of range\n",
      "Training and evaluating Online Boosting...\n",
      "Failed to evaluate Online Boosting: list index out of range\n",
      "Training and evaluating OKD...\n",
      "Failed to evaluate OKD: list index out of range\n",
      "Training and evaluating SRP...\n",
      "Failed to evaluate SRP: list index out of range\n",
      "\n",
      "Results for mouse_card_skimming_abrupt:\n",
      "Error evaluating mouse dataset: \"None of [Index(['Model', 'Accuracy_Mean', 'TPR_Mean', 'FRR_Mean', 'DDA_Mean', 'AL_Mean',\\n       'Delta_Acc_vs_Static', 'p_value_vs_Static'],\\n      dtype='object')] are in the [columns]\"\n",
      "\n",
      "Creating dataset for mouse_phishing_gradual\n",
      "Evaluating models for mouse_phishing_gradual\n",
      "Training and evaluating Random Forest...\n",
      "Failed to evaluate Random Forest: list index out of range\n",
      "Training and evaluating SVM...\n",
      "Failed to evaluate SVM: list index out of range\n",
      "Training and evaluating KNN...\n",
      "Failed to evaluate KNN: list index out of range\n",
      "Training and evaluating XGBoost...\n",
      "Failed to evaluate XGBoost: list index out of range\n",
      "Training and evaluating Voting...\n",
      "Failed to evaluate Voting: list index out of range\n",
      "Training and evaluating Snapshot RF...\n",
      "Failed to evaluate Snapshot RF: list index out of range\n",
      "Training and evaluating Hoeffding Tree...\n",
      "Failed to evaluate Hoeffding Tree: list index out of range\n",
      "Training and evaluating HAT...\n",
      "Failed to evaluate HAT: list index out of range\n",
      "Training and evaluating Leveraging Bagging...\n",
      "Failed to evaluate Leveraging Bagging: list index out of range\n",
      "Training and evaluating Online Boosting...\n",
      "Failed to evaluate Online Boosting: list index out of range\n",
      "Training and evaluating OKD...\n",
      "Failed to evaluate OKD: list index out of range\n",
      "Training and evaluating SRP...\n",
      "Failed to evaluate SRP: list index out of range\n",
      "\n",
      "Results for mouse_phishing_gradual:\n",
      "Error evaluating mouse dataset: \"None of [Index(['Model', 'Accuracy_Mean', 'TPR_Mean', 'FRR_Mean', 'DDA_Mean', 'AL_Mean',\\n       'Delta_Acc_vs_Static', 'p_value_vs_Static'],\\n      dtype='object')] are in the [columns]\"\n",
      "\n",
      "Creating dataset for mouse_identity_theft_incremental\n",
      "Evaluating models for mouse_identity_theft_incremental\n",
      "Training and evaluating Random Forest...\n",
      "Failed to evaluate Random Forest: list index out of range\n",
      "Training and evaluating SVM...\n",
      "Failed to evaluate SVM: list index out of range\n",
      "Training and evaluating KNN...\n",
      "Failed to evaluate KNN: list index out of range\n",
      "Training and evaluating XGBoost...\n",
      "Failed to evaluate XGBoost: list index out of range\n",
      "Training and evaluating Voting...\n",
      "Failed to evaluate Voting: list index out of range\n",
      "Training and evaluating Snapshot RF...\n",
      "Failed to evaluate Snapshot RF: list index out of range\n",
      "Training and evaluating Hoeffding Tree...\n",
      "Failed to evaluate Hoeffding Tree: list index out of range\n",
      "Training and evaluating HAT...\n",
      "Failed to evaluate HAT: list index out of range\n",
      "Training and evaluating Leveraging Bagging...\n",
      "Failed to evaluate Leveraging Bagging: list index out of range\n",
      "Training and evaluating Online Boosting...\n",
      "Failed to evaluate Online Boosting: list index out of range\n",
      "Training and evaluating OKD...\n",
      "Failed to evaluate OKD: list index out of range\n",
      "Training and evaluating SRP...\n",
      "Failed to evaluate SRP: list index out of range\n",
      "\n",
      "Results for mouse_identity_theft_incremental:\n",
      "Error evaluating mouse dataset: \"None of [Index(['Model', 'Accuracy_Mean', 'TPR_Mean', 'FRR_Mean', 'DDA_Mean', 'AL_Mean',\\n       'Delta_Acc_vs_Static', 'p_value_vs_Static'],\\n      dtype='object')] are in the [columns]\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from river.drift import ADWIN, PageHinkley, KSWIN\n",
    "from river.tree import HoeffdingTreeClassifier, HoeffdingAdaptiveTreeClassifier\n",
    "from river.ensemble import LeveragingBaggingClassifier, AdaBoostClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from xgboost import XGBClassifier\n",
    "import copy\n",
    "import os\n",
    "from scipy.stats import bootstrap, ttest_rel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Mock ARF/SRP if not available\n",
    "ENSEMBLE_AVAILABLE = False\n",
    "try:\n",
    "    from river.ensemble import ARFClassifier\n",
    "    EnsembleClassifier = ARFClassifier\n",
    "    ENSEMBLE_NAME = 'ARF'\n",
    "    ENSEMBLE_AVAILABLE = True\n",
    "except ImportError:\n",
    "    try:\n",
    "        from river.ensemble import SRPClassifier\n",
    "        EnsembleClassifier = SRPClassifier\n",
    "        ENSEMBLE_NAME = 'SRP'\n",
    "        ENSEMBLE_AVAILABLE = True\n",
    "    except ImportError:\n",
    "        print(\"Warning: Using RF as ensemble fallback.\")\n",
    "        class EnsembleClassifier(RandomForestClassifier): pass\n",
    "        ENSEMBLE_NAME = 'RF_Fallback'\n",
    "        ENSEMBLE_AVAILABLE = True\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Custom DDM\n",
    "class DDM:\n",
    "    def __init__(self, min_num_instances=30, warning_level=2.0, drift_level=3.0):\n",
    "        self.min_num_instances = min_num_instances\n",
    "        self.warning_level = warning_level\n",
    "        self.drift_level = drift_level\n",
    "        self.mean = 0.0\n",
    "        self.std = 0.0\n",
    "        self.n = 0\n",
    "        self.drift_detected = False\n",
    "        self.mean_min = float('inf')\n",
    "        self.std_min = float('inf')\n",
    "    def add_element(self, error):\n",
    "        self.n += 1\n",
    "        if self.n == 1: self.mean, self.std = error, 0.0\n",
    "        else:\n",
    "            old_mean = self.mean\n",
    "            self.mean += (error - old_mean) / self.n\n",
    "            self.std = np.sqrt((self.std**2 * (self.n - 1) + (error - self.mean) * (error - old_mean)) / self.n)\n",
    "        if self.n >= self.min_num_instances:\n",
    "            if self.mean + self.std * self.warning_level > self.mean_min + self.drift_level * self.std_min:\n",
    "                self.drift_detected = True\n",
    "            else: self.drift_detected = False\n",
    "            if not self.drift_detected:\n",
    "                self.mean_min = min(self.mean_min, self.mean)\n",
    "                self.std_min = min(self.std_min, self.std)\n",
    "        return self.drift_detected\n",
    "\n",
    "# Custom EDDM\n",
    "class EDDM:\n",
    "    def __init__(self, min_num_instances=30, warning_level=0.95, drift_level=0.9):\n",
    "        self.min_num_instances = min_num_instances\n",
    "        self.warning_level = warning_level\n",
    "        self.drift_level = drift_level\n",
    "        self.mean = 0.0\n",
    "        self.std = 0.0\n",
    "        self.n = 0\n",
    "        self.last_error = 0\n",
    "        self.distances = []\n",
    "        self.drift_detected = False\n",
    "        self.max_mean = 0.0\n",
    "    def add_element(self, prediction, true_label):\n",
    "        error = 1 if prediction != true_label else 0\n",
    "        if self.n > 0 and error == 1:\n",
    "            self.distances.append(self.n - self.last_error)\n",
    "        if error == 1:\n",
    "            self.last_error = self.n\n",
    "        self.n += 1\n",
    "        if len(self.distances) > 1:\n",
    "            self.mean = np.mean(self.distances)\n",
    "            self.std = np.std(self.distances)\n",
    "        if self.n >= self.min_num_instances and len(self.distances) > 1:\n",
    "            m = (self.mean + 2 * self.std) / self.max_mean if self.max_mean > 0 else float('inf')\n",
    "            if m < self.drift_level:\n",
    "                self.drift_detected = True\n",
    "            else:\n",
    "                self.drift_detected = False\n",
    "            if not self.drift_detected:\n",
    "                self.max_mean = max(self.max_mean, self.mean + 2 * self.std)\n",
    "        return self.drift_detected\n",
    "\n",
    "# Custom PCDM\n",
    "class PCDM:\n",
    "    def __init__(self, window_size=50, n_permutations=100, alpha=0.01):\n",
    "        self.window_size = window_size\n",
    "        self.n_permutations = n_permutations\n",
    "        self.alpha = alpha\n",
    "        self.reference_window = []\n",
    "        self.current_window = []\n",
    "        self.drift_detected = False\n",
    "    def add_element(self, value):\n",
    "        self.current_window.append(value)\n",
    "        if len(self.current_window) > self.window_size:\n",
    "            self.current_window.pop(0)\n",
    "        if len(self.reference_window) < self.window_size:\n",
    "            self.reference_window.append(value)\n",
    "            return False\n",
    "        if len(self.current_window) == self.window_size:\n",
    "            stat, p_value = self._permutation_test()\n",
    "            self.drift_detected = p_value < self.alpha\n",
    "            if self.drift_detected:\n",
    "                self.reference_window = self.current_window.copy()\n",
    "        return self.drift_detected\n",
    "    def _permutation_test(self):\n",
    "        ref = np.array(self.reference_window)\n",
    "        curr = np.array(self.current_window)\n",
    "        observed_diff = np.abs(np.mean(ref) - np.mean(curr))\n",
    "        combined = np.concatenate([ref, curr])\n",
    "        perm_diffs = []\n",
    "        for _ in range(self.n_permutations):\n",
    "            np.random.shuffle(combined)\n",
    "            perm_ref = combined[:self.window_size]\n",
    "            perm_curr = combined[self.window_size:]\n",
    "            perm_diffs.append(np.abs(np.mean(perm_ref) - np.mean(perm_curr)))\n",
    "        p_value = np.sum(np.array(perm_diffs) >= observed_diff) / self.n_permutations\n",
    "        return observed_diff, p_value\n",
    "\n",
    "# Custom RBFSVMDriftDetector\n",
    "class RBFSVMDriftDetector:\n",
    "    def __init__(self, window_size=50, threshold=0.1):\n",
    "        self.window_size = window_size\n",
    "        self.threshold = threshold\n",
    "        self.reference_window = []\n",
    "        self.current_window = []\n",
    "        self.svm = SVC(kernel='rbf', C=1.0, probability=True)\n",
    "        self.drift_detected = False\n",
    "    def add_element(self, x, y):\n",
    "        self.current_window.append((x, y))\n",
    "        if len(self.current_window) > self.window_size:\n",
    "            self.current_window.pop(0)\n",
    "        if len(self.reference_window) < self.window_size:\n",
    "            self.reference_window.append((x, y))\n",
    "            return False\n",
    "        if len(self.current_window) == self.window_size:\n",
    "            margin_density = self._compute_margin_density()\n",
    "            self.drift_detected = margin_density > self.threshold\n",
    "            if self.drift_detected:\n",
    "                self.reference_window = self.current_window.copy()\n",
    "        return self.drift_detected\n",
    "    def _compute_margin_density(self):\n",
    "        X_ref, y_ref = zip(*self.reference_window)\n",
    "        X_curr, y_curr = zip(*self.current_window)\n",
    "        X_ref, X_curr = np.array(X_ref), np.array(X_curr)\n",
    "        y_ref, y_curr = np.array(y_ref), np.array(y_curr)\n",
    "        self.svm.fit(X_ref, y_ref)\n",
    "        decision_scores = self.svm.decision_function(X_curr)\n",
    "        margin_density = np.mean(np.abs(decision_scores) < 1.0)\n",
    "        return margin_density\n",
    "\n",
    "# Custom HDDM_W\n",
    "class HDDM_W:\n",
    "    def __init__(self, window_size=50, delta=0.001):\n",
    "        self.window_size = window_size\n",
    "        self.delta = delta\n",
    "        self.reference_window = []\n",
    "        self.current_window = []\n",
    "        self.drift_detected = False\n",
    "    def _hellinger_distance(self, hist1, hist2):\n",
    "        return np.sqrt(np.sum((np.sqrt(hist1) - np.sqrt(hist2))**2)) / np.sqrt(2)\n",
    "    def add_element(self, value):\n",
    "        self.current_window.append(value)\n",
    "        if len(self.current_window) > self.window_size:\n",
    "            self.current_window.pop(0)\n",
    "        if len(self.reference_window) < self.window_size:\n",
    "            self.reference_window.append(value)\n",
    "            return False\n",
    "        if len(self.current_window) == self.window_size:\n",
    "            hist_ref, _ = np.histogram(self.reference_window, bins=10, density=True)\n",
    "            hist_curr, _ = np.histogram(self.current_window, bins=10, density=True)\n",
    "            distance = self._hellinger_distance(hist_ref, hist_curr)\n",
    "            self.drift_detected = distance > self.delta\n",
    "            if self.drift_detected:\n",
    "                self.reference_window = self.current_window.copy()\n",
    "        return self.drift_detected\n",
    "\n",
    "# Custom HDDM_A\n",
    "class HDDM_A:\n",
    "    def __init__(self, window_size=50, delta=0.001):\n",
    "        self.window_size = window_size\n",
    "        self.delta = delta\n",
    "        self.reference_window = []\n",
    "        self.current_window = []\n",
    "        self.drift_detected = False\n",
    "    def _hellinger_distance(self, hist1, hist2):\n",
    "        return np.sqrt(np.sum((np.sqrt(hist1) - np.sqrt(hist2))**2)) / np.sqrt(2)\n",
    "    def add_element(self, value):\n",
    "        self.current_window.append(value)\n",
    "        if len(self.current_window) > self.window_size:\n",
    "            self.current_window.pop(0)\n",
    "        if len(self.reference_window) < self.window_size:\n",
    "            self.reference_window.append(value)\n",
    "            return False\n",
    "        if len(self.current_window) == self.window_size:\n",
    "            hist_ref, _ = np.histogram(self.reference_window, bins=10, density=True)\n",
    "            hist_curr, _ = np.histogram(self.current_window, bins=10, density=True)\n",
    "            distance = self._hellinger_distance(hist_ref, hist_curr)\n",
    "            self.drift_detected = distance > self.delta\n",
    "            if self.drift_detected:\n",
    "                self.reference_window = self.current_window.copy()\n",
    "        return self.drift_detected\n",
    "\n",
    "# Improved Autoencoder Drift Detector\n",
    "class AutoencoderDriftDetector:\n",
    "    def __init__(self, threshold_multiplier=3.0, max_iter=500):\n",
    "        self.threshold_multiplier = threshold_multiplier\n",
    "        self.max_iter = max_iter\n",
    "        self.autoencoder = MLPRegressor(hidden_layer_sizes=(10,), max_iter=max_iter, random_state=42)\n",
    "        self.reference_mse = None\n",
    "        self.feature_std = None\n",
    "    def fit(self, X_ref):\n",
    "        self.feature_std = np.std(X_ref, axis=0) + 1e-6\n",
    "        self.autoencoder.fit(X_ref, X_ref)\n",
    "        recon = self.autoencoder.predict(X_ref)\n",
    "        mse = np.mean((X_ref - recon) ** 2, axis=1)\n",
    "        self.reference_mse = np.mean(mse)\n",
    "        self.threshold = self.threshold_multiplier * self.reference_mse\n",
    "    def add_element(self, x, ref=False):\n",
    "        if ref:\n",
    "            return False\n",
    "        recon = self.autoencoder.predict([x])\n",
    "        mse = np.mean(((x - recon) ** 2) / (self.feature_std ** 2))\n",
    "        drift_detected = mse > self.threshold\n",
    "        return drift_detected\n",
    "\n",
    "# Snapshot Ensemble\n",
    "class SnapshotEnsemble:\n",
    "    def __init__(self, base_model, n_snapshots=3):\n",
    "        self.base_model = base_model\n",
    "        self.n_snapshots = n_snapshots\n",
    "        self.snapshots = []\n",
    "    def fit(self, X, y):\n",
    "        self.snapshots = []\n",
    "        for _ in range(self.n_snapshots):\n",
    "            model = copy.deepcopy(self.base_model)\n",
    "            model.fit(X, y)\n",
    "            self.snapshots.append(model)\n",
    "    def predict(self, X):\n",
    "        predictions = np.array([model.predict(X) for model in self.snapshots])\n",
    "        return np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
    "    def predict_proba(self, X):\n",
    "        probas = np.array([model.predict_proba(X) for model in self.snapshots])\n",
    "        return np.mean(probas, axis=0)\n",
    "\n",
    "# Online Knowledge Distillation\n",
    "class OnlineKnowledgeDistillation:\n",
    "    def __init__(self, teacher_model, student_model, alpha=0.5):\n",
    "        self.teacher = teacher_model\n",
    "        self.student = student_model\n",
    "        self.alpha = alpha\n",
    "    def learn_one(self, x, y):\n",
    "        teacher_pred = self.teacher.predict_one(x)\n",
    "        self.student.learn_one(x, y)\n",
    "        return teacher_pred\n",
    "    def predict_one(self, x):\n",
    "        return self.student.predict_one(x)\n",
    "\n",
    "# Keystroke/Mouse Generator using RNN\n",
    "class FeatureGenerator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.LSTM(input_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, input_size)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        return self.linear(out)\n",
    "\n",
    "# Enhanced simulate_attacks with taxonomy-based drifts\n",
    "def simulate_attacks(data, data_type, attack_type, drift_type, n_attack=200, use_generator=False):\n",
    "    attack_data = data.copy().sample(n=n_attack, random_state=42)\n",
    "    if data_type == 'keystroke':\n",
    "        features = ['dwell_time', 'flight_time', 'up_down_time', 'session_duration', 'rhythm']\n",
    "    else:  # mouse\n",
    "        features = ['speed', 'distance', 'delta_x', 'delta_y']\n",
    "    \n",
    "    if use_generator:\n",
    "        input_size = len(features)\n",
    "        generator = FeatureGenerator(input_size)\n",
    "        optimizer = torch.optim.Adam(generator.parameters(), lr=0.001)\n",
    "        criterion = nn.MSELoss()\n",
    "        benign_tensor = torch.tensor(data[features].values[:n_attack], dtype=torch.float32).unsqueeze(1)\n",
    "        for epoch in range(20):\n",
    "            out = generator(benign_tensor)\n",
    "            loss = criterion(out, benign_tensor)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            perturbed = generator(benign_tensor).squeeze(1).numpy()\n",
    "        attack_data[features] = perturbed + np.random.normal(0, 0.1, perturbed.shape)  # Increased noise\n",
    "    else:\n",
    "        # Taxonomy-based noise scales\n",
    "        noise_scales = {'abrupt': 0.15, 'gradual': 0.05, 'recurring': 0.1, 'incremental': 0.07}\n",
    "        base_scale = noise_scales.get(drift_type, 0.05)\n",
    "        for feature in features:\n",
    "            attack_data[feature] += np.random.normal(0, base_scale * attack_data[feature].std(), n_attack)\n",
    "        \n",
    "        if data_type == 'keystroke':\n",
    "            if attack_type == 'session_hijacking' and drift_type == 'abrupt':\n",
    "                attack_data['dwell_time'] *= 1.3 + np.random.uniform(-0.1, 0.1, n_attack)  # Jitter\n",
    "                attack_data['flight_time'] *= 1.4 + np.random.uniform(-0.1, 0.1, n_attack)\n",
    "            elif attack_type == 'mitm' and drift_type == 'recurring':\n",
    "                mask = attack_data.index % 2 == 0\n",
    "                attack_data.loc[mask, 'dwell_time'] *= 1.2 + np.random.uniform(-0.05, 0.05, sum(mask))\n",
    "                attack_data.loc[~mask, 'dwell_time'] *= 0.8 + np.random.uniform(-0.05, 0.05, sum(~mask))\n",
    "            elif attack_type == 'card_skimming' and drift_type == 'abrupt':\n",
    "                attack_data['flight_time'] *= 1.5 + np.random.uniform(-0.1, 0.1, n_attack)\n",
    "                attack_data['rhythm'] += np.random.uniform(-0.1, 0.1, n_attack)\n",
    "            elif attack_type == 'phishing' and drift_type == 'gradual':\n",
    "                attack_data['dwell_time'] += np.linspace(0, 0.2, n_attack) * attack_data['dwell_time'] + np.random.normal(0, 0.07, n_attack)\n",
    "            elif attack_type == 'identity_theft' and drift_type == 'incremental':\n",
    "                attack_data['dwell_time'] += np.linspace(0, 0.1, n_attack) * attack_data['dwell_time'] + np.random.normal(0, 0.05, n_attack)\n",
    "        else:  # mouse\n",
    "            if attack_type == 'session_hijacking' and drift_type == 'abrupt':\n",
    "                attack_data['speed'] *= 1.3 + np.random.uniform(-0.1, 0.1, n_attack)\n",
    "                attack_data['distance'] *= 1.4 + np.random.uniform(-0.1, 0.1, n_attack)\n",
    "            elif attack_type == 'mitm' and drift_type == 'recurring':\n",
    "                mask = attack_data.index % 2 == 0\n",
    "                attack_data.loc[mask, 'speed'] *= 1.2 + np.random.uniform(-0.05, 0.05, sum(mask))\n",
    "                attack_data.loc[~mask, 'speed'] *= 0.8 + np.random.uniform(-0.05, 0.05, sum(~mask))\n",
    "            elif attack_type == 'card_skimming' and drift_type == 'abrupt':\n",
    "                attack_data['speed'] *= 1.5 + np.random.uniform(-0.1, 0.1, n_attack)\n",
    "                attack_data['distance'] += np.random.uniform(-0.1, 0.1, n_attack)\n",
    "            elif attack_type == 'phishing' and drift_type == 'gradual':\n",
    "                attack_data['speed'] += np.linspace(0, 0.2, n_attack) * attack_data['speed'] + np.random.normal(0, 0.07, n_attack)\n",
    "            elif attack_type == 'identity_theft' and drift_type == 'incremental':\n",
    "                attack_data['speed'] += np.linspace(0, 0.1, n_attack) * attack_data['speed'] + np.random.normal(0, 0.05, n_attack)\n",
    "        attack_data['label'] = 1\n",
    "    return attack_data\n",
    "\n",
    "# Load and preprocess data\n",
    "def load_data(data_file, data_type):\n",
    "    try:\n",
    "        df = pd.read_csv(data_file)\n",
    "        print(f\"Initial {data_type} Rows: {len(df)}\")\n",
    "        if data_type == 'keystroke':\n",
    "            features = ['dwell_time', 'flight_time', 'up_down_time', 'session_duration', 'rhythm']\n",
    "        else:  # mouse\n",
    "            features = ['speed', 'distance']\n",
    "            if 'delta' in df.columns:\n",
    "                try:\n",
    "                    df['delta_x'] = df['delta'].apply(lambda x: float(x.split(',')[0].strip('() ')) if isinstance(x, str) else x[0] if isinstance(x, (list, tuple)) else np.nan)\n",
    "                    df['delta_y'] = df['delta'].apply(lambda x: float(x.split(',')[1].strip('() ')) if isinstance(x, str) else x[1] if isinstance(x, (list, tuple)) else np.nan)\n",
    "                    features += ['delta_x', 'delta_y']\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Failed to parse 'delta' column in {data_type} dataset. Error: {e}\")\n",
    "                    df = df.drop(columns=['delta'])\n",
    "        for feature in features:\n",
    "            if feature not in df.columns:\n",
    "                raise ValueError(f\"Feature '{feature}' not found in {data_type} dataset\")\n",
    "        df = df.dropna(subset=features)\n",
    "        print(f\"{data_type} Rows after NaN drop: {len(df)}\")\n",
    "        df['label'] = 0  # Benign\n",
    "        return df, features\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {data_type} dataset: {e}. Using synthetic data.\")\n",
    "        return generate_synthetic_data(data_type)\n",
    "\n",
    "# Synthetic data generator\n",
    "def generate_synthetic_data(data_type, n_samples=1000):\n",
    "    np.random.seed(42)\n",
    "    if data_type == 'keystroke':\n",
    "        df = pd.DataFrame({\n",
    "            'dwell_time': np.random.normal(100, 20, n_samples),\n",
    "            'flight_time': np.random.normal(150, 30, n_samples),\n",
    "            'up_down_time': np.random.normal(120, 25, n_samples),\n",
    "            'session_duration': np.random.normal(500, 100, n_samples),\n",
    "            'rhythm': np.random.normal(0.8, 0.1, n_samples),\n",
    "            'label': np.random.choice([0, 1], n_samples, p=[0.8, 0.2])  # 80% benign\n",
    "        })\n",
    "        features = ['dwell_time', 'flight_time', 'up_down_time', 'session_duration', 'rhythm']\n",
    "    else:  # mouse\n",
    "        times = np.cumsum(np.random.exponential(0.1, n_samples))\n",
    "        x = np.cumsum(np.random.normal(0, 10, n_samples))\n",
    "        y = np.cumsum(np.random.normal(0, 10, n_samples))\n",
    "        delta_x = np.diff(x, prepend=x[0])\n",
    "        delta_y = np.diff(y, prepend=y[0])\n",
    "        dt = np.diff(times, prepend=times[0])\n",
    "        speed = np.sqrt(delta_x**2 + delta_y**2) / (dt + 1e-6)\n",
    "        distance = np.sqrt(delta_x**2 + delta_y**2)\n",
    "        df = pd.DataFrame({\n",
    "            'speed': speed,\n",
    "            'distance': distance,\n",
    "            'delta_x': delta_x,\n",
    "            'delta_y': delta_y,\n",
    "            'label': np.random.choice([0, 1], n_samples, p=[0.8, 0.2])\n",
    "        })\n",
    "        features = ['speed', 'distance', 'delta_x', 'delta_y']\n",
    "    return df, features\n",
    "\n",
    "# Combine benign and attack data\n",
    "def create_combined_dataset(benign_df, data_type, attack_type, drift_type, n_attack=200, use_generator=False):\n",
    "    attack_df = simulate_attacks(benign_df, data_type, attack_type, drift_type, n_attack, use_generator)\n",
    "    combined_df = pd.concat([benign_df, attack_df], ignore_index=True)\n",
    "    output_dir = '/Users/festusedward-n/Documents/Datasets'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_file = f'{output_dir}/{data_type}_{attack_type}_{drift_type}_data.csv'\n",
    "    combined_df.to_csv(output_file, index=False)\n",
    "    return combined_df\n",
    "\n",
    "# Tune detector based on drift type\n",
    "def get_tuned_detector(detector_class, drift_type):\n",
    "    if drift_type in ['gradual', 'incremental', 'recurring']:\n",
    "        if detector_class == ADWIN:\n",
    "            return ADWIN(delta=0.0001)\n",
    "        elif detector_class == PageHinkley:\n",
    "            return PageHinkley(threshold=10)\n",
    "        elif detector_class == KSWIN:\n",
    "            return KSWIN(alpha=0.005)\n",
    "        elif detector_class == PCDM:\n",
    "            return PCDM(alpha=0.005)\n",
    "        elif detector_class == RBFSVMDriftDetector:\n",
    "            return RBFSVMDriftDetector(threshold=0.05)\n",
    "        elif detector_class == HDDM_W:\n",
    "            return HDDM_W(delta=0.0001)\n",
    "        elif detector_class == HDDM_A:\n",
    "            return HDDM_A(delta=0.0001)\n",
    "        elif detector_class == DDM:\n",
    "            return DDM(drift_level=2.0)\n",
    "        elif detector_class == EDDM:\n",
    "            return EDDM(drift_level=0.8)\n",
    "    else:  # Abrupt\n",
    "        if detector_class == ADWIN:\n",
    "            return ADWIN(delta=0.001)\n",
    "        return detector_class()\n",
    "\n",
    "# Evaluate batch models\n",
    "def evaluate_batch_model(name, model, X_scaled, y, features, window_size, step_size, true_drifts, drift_points, output_dir, drift_type, adaptive=True):\n",
    "    window_results = []\n",
    "    adaptation_latencies = []\n",
    "    window_accs = []\n",
    "    base_model = copy.deepcopy(model)\n",
    "    autoencoder = AutoencoderDriftDetector(threshold_multiplier=3.0, max_iter=500)\n",
    "    is_first_window = True\n",
    "\n",
    "    detector_classes = [ADWIN, PageHinkley, KSWIN, DDM, EDDM, PCDM, RBFSVMDriftDetector, HDDM_W, HDDM_A]\n",
    "    detectors = {cls.__name__: get_tuned_detector(cls, drift_type) for cls in detector_classes}\n",
    "    detectors['AutoencoderDriftDetector'] = autoencoder\n",
    "\n",
    "    for start in range(0, len(X_scaled) - window_size + 1, step_size):\n",
    "        end = start + window_size\n",
    "        X_window = X_scaled[start:end]\n",
    "        y_window = y[start:end]\n",
    "        if len(np.unique(y_window)) < 2:\n",
    "            continue\n",
    "        try:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_window, y_window, test_size=0.2, random_state=42, stratify=y_window)\n",
    "            if len(np.unique(y_train)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                continue\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "            tn, fp, fn, tp = cm.ravel() if cm.shape == (2, 2) else (0, 0, 0, 0)\n",
    "            tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "            tar = recall_score(y_test, y_pred, average='macro', zero_division=0) if len(np.unique(y_test)) > 1 else 0\n",
    "            frr = 1 - tar\n",
    "            window_metrics = {\n",
    "                'Model': name,\n",
    "                'Window': start,\n",
    "                'Accuracy': accuracy_score(y_test, y_pred),\n",
    "                'Precision': precision_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "                'Recall': recall_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "                'F1-Score': f1_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "                'TPR': tpr,\n",
    "                'FPR': fpr,\n",
    "                'TAR': tar,\n",
    "                'FRR': frr\n",
    "            }\n",
    "            if hasattr(model, 'predict_proba'):\n",
    "                y_proba = model.predict_proba(X_test)[:, 1]\n",
    "                window_metrics['ROC-AUC'] = roc_auc_score(y_test, y_proba) if len(np.unique(y_test)) > 1 else np.nan\n",
    "            window_results.append(window_metrics)\n",
    "            window_accs.append(window_metrics['Accuracy'])\n",
    "\n",
    "            if is_first_window:\n",
    "                autoencoder.fit(X_train)\n",
    "                is_first_window = False\n",
    "\n",
    "            drift_detected = False\n",
    "            for i in range(len(X_window)):\n",
    "                x = X_window[i]\n",
    "                y_true = y_window[i]\n",
    "                pred = model.predict([x])[0]\n",
    "                error = 1.0 if pred != y_true else 0.0\n",
    "                global_idx = start + i\n",
    "                for det_name, det in detectors.items():\n",
    "                    if det_name == 'DDM':\n",
    "                        update = det.add_element(error)\n",
    "                    elif det_name == 'EDDM':\n",
    "                        update = det.add_element(pred, y_true)\n",
    "                    elif det_name == 'PCDM':\n",
    "                        update = det.add_element(x[0])\n",
    "                    elif det_name == 'RBFSVMDriftDetector':\n",
    "                        update = det.add_element(x, y_true)\n",
    "                    else:\n",
    "                        update = det.update(x[0])\n",
    "                    if update:\n",
    "                        key = f'{det_name.lower()}_{features[0]}'\n",
    "                        if key in drift_points[name]:\n",
    "                            drift_points[name][key].append(global_idx)\n",
    "                        drift_detected = True\n",
    "                        adaptation_latencies.append(global_idx)\n",
    "\n",
    "            if adaptive and drift_detected:\n",
    "                model = copy.deepcopy(base_model)\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred_post = model.predict(X_test)\n",
    "                window_metrics['Post-Accuracy'] = accuracy_score(y_test, y_pred_post)\n",
    "\n",
    "            window_results[-1] = window_metrics\n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating {name} at window {start}: {e}\")\n",
    "    return window_results, adaptation_latencies, window_accs\n",
    "\n",
    "# Evaluate streaming models\n",
    "def evaluate_streaming_model(name, model, X_scaled, y, features, window_size, step_size, true_drifts, drift_points, output_dir, drift_type, adaptive=True):\n",
    "    window_results = []\n",
    "    adaptation_latencies = []\n",
    "    window_accs = []\n",
    "    base_model = copy.deepcopy(model)\n",
    "    autoencoder = AutoencoderDriftDetector(threshold_multiplier=3.0, max_iter=500)\n",
    "    is_first_window = True\n",
    "\n",
    "    detector_classes = [ADWIN, PageHinkley, KSWIN, DDM, EDDM, PCDM, RBFSVMDriftDetector, HDDM_W, HDDM_A]\n",
    "    detectors = {cls.__name__: get_tuned_detector(cls, drift_type) for cls in detector_classes}\n",
    "    detectors['AutoencoderDriftDetector'] = autoencoder\n",
    "\n",
    "    for start in range(0, len(X_scaled) - window_size + 1, step_size):\n",
    "        end = start + window_size\n",
    "        X_window = X_scaled[start:end]\n",
    "        y_window = y[start:end]\n",
    "        if len(np.unique(y_window)) < 2:\n",
    "            continue\n",
    "        try:\n",
    "            y_pred = []\n",
    "            for i in range(1, len(X_window)):\n",
    "                sample = dict(zip(features, X_window[i]))\n",
    "                pred = model.predict_one(sample) or 0\n",
    "                y_pred.append(pred)\n",
    "                model.learn_one(sample, y_window[i])\n",
    "            y_true = y_window[1:]\n",
    "            if len(y_pred) == 0:\n",
    "                continue\n",
    "            cm = confusion_matrix(y_true, y_pred)\n",
    "            tn, fp, fn, tp = cm.ravel() if cm.shape == (2, 2) else (0, 0, 0, 0)\n",
    "            tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "            tar = recall_score(y_true, y_pred, average='macro', zero_division=0) if len(np.unique(y_true)) > 1 else 0\n",
    "            frr = 1 - tar\n",
    "            window_metrics = {\n",
    "                'Model': name,\n",
    "                'Window': start,\n",
    "                'Accuracy': accuracy_score(y_true, y_pred),\n",
    "                'Precision': precision_score(y_true, y_pred, average='weighted', zero_division=0),\n",
    "                'Recall': recall_score(y_true, y_pred, average='weighted', zero_division=0),\n",
    "                'F1-Score': f1_score(y_true, y_pred, average='weighted', zero_division=0),\n",
    "                'TPR': tpr,\n",
    "                'FPR': fpr,\n",
    "                'TAR': tar,\n",
    "                'FRR': frr\n",
    "            }\n",
    "            window_results.append(window_metrics)\n",
    "            window_accs.append(window_metrics['Accuracy'])\n",
    "\n",
    "            if is_first_window:\n",
    "                autoencoder.fit(X_window[:int(0.8 * len(X_window))])\n",
    "                is_first_window = False\n",
    "\n",
    "            drift_detected = False\n",
    "            for i in range(len(X_window)):\n",
    "                x = X_window[i]\n",
    "                y_true = y_window[i]\n",
    "                pred = model.predict_one(dict(zip(features, x))) or 0\n",
    "                error = 1.0 if pred != y_true else 0.0\n",
    "                global_idx = start + i\n",
    "                for det_name, det in detectors.items():\n",
    "                    if det_name == 'DDM':\n",
    "                        update = det.add_element(error)\n",
    "                    elif det_name == 'EDDM':\n",
    "                        update = det.add_element(pred, y_true)\n",
    "                    elif det_name == 'PCDM':\n",
    "                        update = det.add_element(x[0])\n",
    "                    elif det_name == 'RBFSVMDriftDetector':\n",
    "                        update = det.add_element(x, y_true)\n",
    "                    else:\n",
    "                        update = det.update(x[0])\n",
    "                    if update:\n",
    "                        key = f'{det_name.lower()}_{features[0]}'\n",
    "                        if key in drift_points[name]:\n",
    "                            drift_points[name][key].append(global_idx)\n",
    "                        drift_detected = True\n",
    "                        adaptation_latencies.append(global_idx)\n",
    "\n",
    "            if adaptive and drift_detected:\n",
    "                model = copy.deepcopy(base_model)\n",
    "                for j in range(len(X_window)):\n",
    "                    sample = dict(zip(features, X_window[j]))\n",
    "                    model.learn_one(sample, y_window[j])\n",
    "                y_pred_post = [model.predict_one(dict(zip(features, x))) or 0 for x in X_window[1:]]\n",
    "                window_metrics['Post-Accuracy'] = accuracy_score(y_true, y_pred_post)\n",
    "\n",
    "            window_results[-1] = window_metrics\n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating {name} at window {start}: {e}\")\n",
    "    return window_results, adaptation_latencies, window_accs\n",
    "\n",
    "# Main evaluation function with DDA and AL\n",
    "def evaluate_models(data_df, data_type, features, attack_type, drift_type, window_size=100, step_size=10):\n",
    "    try:\n",
    "        X = data_df[features].values\n",
    "        y = data_df['label'].values\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        models = {\n",
    "            'Random Forest': RandomForestClassifier(n_estimators=50, max_depth=3, min_samples_split=10, random_state=42),  # Reduced complexity\n",
    "            'SVM': SVC(kernel='rbf', C=0.5, probability=True, random_state=42),\n",
    "            'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "            'XGBoost': XGBClassifier(n_estimators=50, max_depth=2, learning_rate=0.01, reg_lambda=1.0, random_state=42),\n",
    "            'Voting': VotingClassifier(estimators=[\n",
    "                ('rf', RandomForestClassifier(n_estimators=50, max_depth=3, min_samples_split=10, random_state=42)),\n",
    "                ('svm', SVC(kernel='rbf', C=0.5, probability=True, random_state=42)),\n",
    "                ('knn', KNeighborsClassifier(n_neighbors=5))\n",
    "            ], voting='soft'),\n",
    "            'Snapshot RF': SnapshotEnsemble(RandomForestClassifier(n_estimators=50, max_depth=3, min_samples_split=10, random_state=42), n_snapshots=2),\n",
    "            'Hoeffding Tree': HoeffdingTreeClassifier(grace_period=50, delta=0.01),  # Corrected parameter\n",
    "            'HAT': HoeffdingAdaptiveTreeClassifier(grace_period=50, delta=0.01),    # Corrected parameter\n",
    "            'Leveraging Bagging': LeveragingBaggingClassifier(model=HoeffdingTreeClassifier(grace_period=50, delta=0.01), n_models=5),\n",
    "            'Online Boosting': AdaBoostClassifier(model=HoeffdingTreeClassifier(grace_period=50, delta=0.01), n_models=5),\n",
    "            'OKD': OnlineKnowledgeDistillation(\n",
    "                teacher_model=HoeffdingAdaptiveTreeClassifier(grace_period=50, delta=0.01),\n",
    "                student_model=HoeffdingTreeClassifier(grace_period=50, delta=0.01),\n",
    "                alpha=0.5\n",
    "            )\n",
    "        }\n",
    "        if ENSEMBLE_AVAILABLE:\n",
    "            if ENSEMBLE_NAME == 'ARF':\n",
    "                models[ENSEMBLE_NAME] = EnsembleClassifier(n_estimators=5)\n",
    "            else:  # SRP\n",
    "                models[ENSEMBLE_NAME] = EnsembleClassifier(n_models=5)\n",
    "        \n",
    "        results = []\n",
    "        detectors = ['adwin', 'page_hinkley', 'ddm', 'eddm', 'kswin', 'pcdm', 'rbf_svm', 'hddm_w', 'hddm_a', 'autoencoder']\n",
    "        drift_points = {name: {f'{detector}_{feature}': [] for detector in detectors for feature in features} for name in models}\n",
    "        true_drifts = [len(data_df[data_df['label'] == 0]) + 50]  # Drift near attack start\n",
    "        adaptation_latencies = {name: [] for name in models}\n",
    "        output_dir = f'/Users/festusedward-n/Documents/Datasets/{data_type}_{attack_type}_{drift_type}'\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        streaming_models = ['Hoeffding Tree', 'HAT', ENSEMBLE_NAME, 'Leveraging Bagging', 'Online Boosting', 'OKD']\n",
    "        \n",
    "        for name, model in models.items():\n",
    "            print(f\"Training and evaluating {name}...\")\n",
    "            try:\n",
    "                eval_func = evaluate_streaming_model if name in streaming_models else evaluate_batch_model\n",
    "                \n",
    "                # Adaptive run with consensus-based drift\n",
    "                adaptive_results, adaptive_latencies, adaptive_accs = eval_func(name, model, X_scaled, y, features, window_size, step_size, true_drifts, drift_points, output_dir, drift_type, adaptive=True)\n",
    "                adaptation_latencies[name] = adaptive_latencies\n",
    "                \n",
    "                # Static ablation run\n",
    "                static_results, _, static_accs = eval_func(name, model, X_scaled, y, features, window_size, step_size, true_drifts, drift_points, output_dir, drift_type, adaptive=False)\n",
    "                \n",
    "                # Aggregate adaptive results\n",
    "                aggregated = {\n",
    "                    'Model': name,\n",
    "                    'Accuracy_Mean': np.mean([r['Accuracy'] for r in adaptive_results]),\n",
    "                    'Accuracy_CI_Low': bootstrap_ci([r['Accuracy'] for r in adaptive_results])[0],\n",
    "                    'Accuracy_CI_High': bootstrap_ci([r['Accuracy'] for r in adaptive_results])[1],\n",
    "                    'TPR_Mean': np.mean([r['TPR'] for r in adaptive_results]),\n",
    "                    'TPR_CI_Low': bootstrap_ci([r['TPR'] for r in adaptive_results])[0],\n",
    "                    'TPR_CI_High': bootstrap_ci([r['TPR'] for r in adaptive_results])[1],\n",
    "                    'FRR_Mean': np.mean([r['FRR'] for r in adaptive_results]),\n",
    "                    'FRR_CI_Low': bootstrap_ci([r['FRR'] for r in adaptive_results])[0],\n",
    "                    'FRR_CI_High': bootstrap_ci([r['FRR'] for r in adaptive_results])[1],\n",
    "                    'Precision_Mean': np.mean([r['Precision'] for r in adaptive_results]),\n",
    "                    'Recall_Mean': np.mean([r['Recall'] for r in adaptive_results]),\n",
    "                    'F1_Mean': np.mean([r['F1-Score'] for r in adaptive_results])\n",
    "                }\n",
    "                \n",
    "                # t-test vs static\n",
    "                if len(adaptive_accs) == len(static_accs) and adaptive_accs and static_accs:\n",
    "                    t_stat, p_val = ttest_rel(adaptive_accs, static_accs)\n",
    "                    aggregated['Delta_Acc_vs_Static'] = np.mean(adaptive_accs) - np.mean(static_accs)\n",
    "                    aggregated['p_value_vs_Static'] = p_val\n",
    "                else:\n",
    "                    aggregated['Delta_Acc_vs_Static'] = np.nan\n",
    "                    aggregated['p_value_vs_Static'] = np.nan\n",
    "                \n",
    "                # Compute DDA and AL\n",
    "                total_detections = sum(len(v) for v in drift_points[name].values())\n",
    "                correct_detections = sum(len([d for d in detected if any(abs(d - t) < 50 for t in true_drifts)]) for detected in drift_points[name].values())\n",
    "                aggregated['DDA_Mean'] = correct_detections / max(1, total_detections) if total_detections else 0.0\n",
    "                aggregated['AL_Mean'] = np.mean(adaptation_latencies[name]) if adaptation_latencies[name] else float('inf')\n",
    "                \n",
    "                if 'Post-Accuracy' in adaptive_results[0]:\n",
    "                    aggregated['Post_Accuracy_Mean'] = np.mean([r['Post-Accuracy'] for r in adaptive_results])\n",
    "                \n",
    "                if name in ['Random Forest', 'SVM', 'KNN', 'XGBoost', 'Voting', 'Snapshot RF']:\n",
    "                    roc_vals = [r['ROC-AUC'] for r in adaptive_results if 'ROC-AUC' in r and not np.isnan(r['ROC-AUC'])]\n",
    "                    aggregated['ROC_AUC_Mean'] = np.mean(roc_vals)\n",
    "                \n",
    "                results.append(aggregated)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to evaluate {name}: {e}\")\n",
    "        \n",
    "        results_df = pd.DataFrame(results)\n",
    "        output_file = f'{output_dir}/results.csv'\n",
    "        results_df.to_csv(output_file, index=False)\n",
    "        \n",
    "        print(f\"\\nResults for {data_type}_{attack_type}_{drift_type}:\")\n",
    "        print(results_df[['Model', 'Accuracy_Mean', 'TPR_Mean', 'FRR_Mean', 'DDA_Mean', 'AL_Mean', 'Delta_Acc_vs_Static', 'p_value_vs_Static']])\n",
    "        print(\"Drift Points summary:\", {k: len(v) for k, v in drift_points.items() if v})\n",
    "        \n",
    "        # Plotting (simplified)\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.savefig(f'{output_dir}/f1.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        return results_df, drift_points\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating {data_type} dataset: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Load and preprocess data\n",
    "def load_data(data_file, data_type):\n",
    "    try:\n",
    "        df = pd.read_csv(data_file)\n",
    "        print(f\"Initial {data_type} Rows: {len(df)}\")\n",
    "        if data_type == 'keystroke':\n",
    "            features = ['dwell_time', 'flight_time', 'up_down_time', 'session_duration', 'rhythm']\n",
    "        else:  # mouse\n",
    "            features = ['speed', 'distance']\n",
    "            if 'delta' in df.columns:\n",
    "                try:\n",
    "                    df['delta_x'] = df['delta'].apply(lambda x: float(x.split(',')[0].strip('() ')) if isinstance(x, str) else x[0] if isinstance(x, (list, tuple)) else np.nan)\n",
    "                    df['delta_y'] = df['delta'].apply(lambda x: float(x.split(',')[1].strip('() ')) if isinstance(x, str) else x[1] if isinstance(x, (list, tuple)) else np.nan)\n",
    "                    features += ['delta_x', 'delta_y']\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Failed to parse 'delta' column in {data_type} dataset. Error: {e}\")\n",
    "                    df = df.drop(columns=['delta'])\n",
    "        for feature in features:\n",
    "            if feature not in df.columns:\n",
    "                raise ValueError(f\"Feature '{feature}' not found in {data_type} dataset\")\n",
    "        df = df.dropna(subset=features)\n",
    "        print(f\"{data_type} Rows after NaN drop: {len(df)}\")\n",
    "        df['label'] = 0  # Benign\n",
    "        return df, features\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {data_type} dataset: {e}. Using synthetic data.\")\n",
    "        return generate_synthetic_data(data_type)\n",
    "\n",
    "# Synthetic data generator\n",
    "def generate_synthetic_data(data_type, n_samples=1000):\n",
    "    np.random.seed(42)\n",
    "    if data_type == 'keystroke':\n",
    "        df = pd.DataFrame({\n",
    "            'dwell_time': np.random.normal(100, 20, n_samples),\n",
    "            'flight_time': np.random.normal(150, 30, n_samples),\n",
    "            'up_down_time': np.random.normal(120, 25, n_samples),\n",
    "            'session_duration': np.random.normal(500, 100, n_samples),\n",
    "            'rhythm': np.random.normal(0.8, 0.1, n_samples),\n",
    "            'label': np.random.choice([0, 1], n_samples, p=[0.8, 0.2])  # 80% benign\n",
    "        })\n",
    "        features = ['dwell_time', 'flight_time', 'up_down_time', 'session_duration', 'rhythm']\n",
    "    else:  # mouse\n",
    "        times = np.cumsum(np.random.exponential(0.1, n_samples))\n",
    "        x = np.cumsum(np.random.normal(0, 10, n_samples))\n",
    "        y = np.cumsum(np.random.normal(0, 10, n_samples))\n",
    "        delta_x = np.diff(x, prepend=x[0])\n",
    "        delta_y = np.diff(y, prepend=y[0])\n",
    "        dt = np.diff(times, prepend=times[0])\n",
    "        speed = np.sqrt(delta_x**2 + delta_y**2) / (dt + 1e-6)\n",
    "        distance = np.sqrt(delta_x**2 + delta_y**2)\n",
    "        df = pd.DataFrame({\n",
    "            'speed': speed,\n",
    "            'distance': distance,\n",
    "            'delta_x': delta_x,\n",
    "            'delta_y': delta_y,\n",
    "            'label': np.random.choice([0, 1], n_samples, p=[0.8, 0.2])\n",
    "        })\n",
    "        features = ['speed', 'distance', 'delta_x', 'delta_y']\n",
    "    return df, features\n",
    "\n",
    "# Combine benign and attack data\n",
    "def create_combined_dataset(benign_df, data_type, attack_type, drift_type, n_attack=200, use_generator=False):\n",
    "    attack_df = simulate_attacks(benign_df, data_type, attack_type, drift_type, n_attack, use_generator)\n",
    "    combined_df = pd.concat([benign_df, attack_df], ignore_index=True)\n",
    "    output_dir = '/Users/festusedward-n/Documents/Datasets'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_file = f'{output_dir}/{data_type}_{attack_type}_{drift_type}_data.csv'\n",
    "    combined_df.to_csv(output_file, index=False)\n",
    "    return combined_df\n",
    "\n",
    "# Tune detector based on drift type\n",
    "def get_tuned_detector(detector_class, drift_type):\n",
    "    if drift_type in ['gradual', 'incremental', 'recurring']:\n",
    "        if detector_class == ADWIN:\n",
    "            return ADWIN(delta=0.0001)\n",
    "        elif detector_class == PageHinkley:\n",
    "            return PageHinkley(threshold=10)\n",
    "        elif detector_class == KSWIN:\n",
    "            return KSWIN(alpha=0.005)\n",
    "        elif detector_class == PCDM:\n",
    "            return PCDM(alpha=0.005)\n",
    "        elif detector_class == RBFSVMDriftDetector:\n",
    "            return RBFSVMDriftDetector(threshold=0.05)\n",
    "        elif detector_class == HDDM_W:\n",
    "            return HDDM_W(delta=0.0001)\n",
    "        elif detector_class == HDDM_A:\n",
    "            return HDDM_A(delta=0.0001)\n",
    "        elif detector_class == DDM:\n",
    "            return DDM(drift_level=2.0)\n",
    "        elif detector_class == EDDM:\n",
    "            return EDDM(drift_level=0.8)\n",
    "    else:  # Abrupt\n",
    "        if detector_class == ADWIN:\n",
    "            return ADWIN(delta=0.001)\n",
    "        return detector_class()\n",
    "\n",
    "# Evaluate batch models\n",
    "def evaluate_batch_model(name, model, X_scaled, y, features, window_size, step_size, true_drifts, drift_points, output_dir, drift_type, adaptive=True):\n",
    "    window_results = []\n",
    "    adaptation_latencies = []\n",
    "    window_accs = []\n",
    "    base_model = copy.deepcopy(model)\n",
    "    autoencoder = AutoencoderDriftDetector(threshold_multiplier=3.0, max_iter=500)\n",
    "    is_first_window = True\n",
    "\n",
    "    detector_classes = [ADWIN, PageHinkley, KSWIN, DDM, EDDM, PCDM, RBFSVMDriftDetector, HDDM_W, HDDM_A]\n",
    "    detectors = {cls.__name__: get_tuned_detector(cls, drift_type) for cls in detector_classes}\n",
    "    detectors['AutoencoderDriftDetector'] = autoencoder\n",
    "\n",
    "    for start in range(0, len(X_scaled) - window_size + 1, step_size):\n",
    "        end = start + window_size\n",
    "        X_window = X_scaled[start:end]\n",
    "        y_window = y[start:end]\n",
    "        if len(np.unique(y_window)) < 2:\n",
    "            continue\n",
    "        try:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_window, y_window, test_size=0.2, random_state=42, stratify=y_window)\n",
    "            if len(np.unique(y_train)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                continue\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "            tn, fp, fn, tp = cm.ravel() if cm.shape == (2, 2) else (0, 0, 0, 0)\n",
    "            tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "            tar = recall_score(y_test, y_pred, average='macro', zero_division=0) if len(np.unique(y_test)) > 1 else 0\n",
    "            frr = 1 - tar\n",
    "            window_metrics = {\n",
    "                'Model': name,\n",
    "                'Window': start,\n",
    "                'Accuracy': accuracy_score(y_test, y_pred),\n",
    "                'Precision': precision_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "                'Recall': recall_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "                'F1-Score': f1_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "                'TPR': tpr,\n",
    "                'FPR': fpr,\n",
    "                'TAR': tar,\n",
    "                'FRR': frr\n",
    "            }\n",
    "            if hasattr(model, 'predict_proba'):\n",
    "                y_proba = model.predict_proba(X_test)[:, 1]\n",
    "                window_metrics['ROC-AUC'] = roc_auc_score(y_test, y_proba) if len(np.unique(y_test)) > 1 else np.nan\n",
    "            window_results.append(window_metrics)\n",
    "            window_accs.append(window_metrics['Accuracy'])\n",
    "\n",
    "            if is_first_window:\n",
    "                autoencoder.fit(X_train)\n",
    "                is_first_window = False\n",
    "\n",
    "            drift_detected = False\n",
    "            for i in range(len(X_window)):\n",
    "                x = X_window[i]\n",
    "                y_true = y_window[i]\n",
    "                pred = model.predict([x])[0]\n",
    "                error = 1.0 if pred != y_true else 0.0\n",
    "                global_idx = start + i\n",
    "                for det_name, det in detectors.items():\n",
    "                    if det_name == 'DDM':\n",
    "                        update = det.add_element(error)\n",
    "                    elif det_name == 'EDDM':\n",
    "                        update = det.add_element(pred, y_true)\n",
    "                    elif det_name == 'PCDM':\n",
    "                        update = det.add_element(x[0])\n",
    "                    elif det_name == 'RBFSVMDriftDetector':\n",
    "                        update = det.add_element(x, y_true)\n",
    "                    else:\n",
    "                        update = det.update(x[0])\n",
    "                    if update:\n",
    "                        key = f'{det_name.lower()}_{features[0]}'\n",
    "                        if key in drift_points[name]:\n",
    "                            drift_points[name][key].append(global_idx)\n",
    "                        drift_detected = True\n",
    "                        adaptation_latencies.append(global_idx)\n",
    "\n",
    "            if adaptive and drift_detected:\n",
    "                model = copy.deepcopy(base_model)\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred_post = model.predict(X_test)\n",
    "                window_metrics['Post-Accuracy'] = accuracy_score(y_test, y_pred_post)\n",
    "\n",
    "            window_results[-1] = window_metrics\n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating {name} at window {start}: {e}\")\n",
    "    return window_results, adaptation_latencies, window_accs\n",
    "\n",
    "# Evaluate streaming models\n",
    "def evaluate_streaming_model(name, model, X_scaled, y, features, window_size, step_size, true_drifts, drift_points, output_dir, drift_type, adaptive=True):\n",
    "    window_results = []\n",
    "    adaptation_latencies = []\n",
    "    window_accs = []\n",
    "    base_model = copy.deepcopy(model)\n",
    "    autoencoder = AutoencoderDriftDetector(threshold_multiplier=3.0, max_iter=500)\n",
    "    is_first_window = True\n",
    "\n",
    "    detector_classes = [ADWIN, PageHinkley, KSWIN, DDM, EDDM, PCDM, RBFSVMDriftDetector, HDDM_W, HDDM_A]\n",
    "    detectors = {cls.__name__: get_tuned_detector(cls, drift_type) for cls in detector_classes}\n",
    "    detectors['AutoencoderDriftDetector'] = autoencoder\n",
    "\n",
    "    for start in range(0, len(X_scaled) - window_size + 1, step_size):\n",
    "        end = start + window_size\n",
    "        X_window = X_scaled[start:end]\n",
    "        y_window = y[start:end]\n",
    "        if len(np.unique(y_window)) < 2:\n",
    "            continue\n",
    "        try:\n",
    "            y_pred = []\n",
    "            for i in range(1, len(X_window)):\n",
    "                sample = dict(zip(features, X_window[i]))\n",
    "                pred = model.predict_one(sample) or 0\n",
    "                y_pred.append(pred)\n",
    "                model.learn_one(sample, y_window[i])\n",
    "            y_true = y_window[1:]\n",
    "            if len(y_pred) == 0:\n",
    "                continue\n",
    "            cm = confusion_matrix(y_true, y_pred)\n",
    "            tn, fp, fn, tp = cm.ravel() if cm.shape == (2, 2) else (0, 0, 0, 0)\n",
    "            tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "            tar = recall_score(y_true, y_pred, average='macro', zero_division=0) if len(np.unique(y_true)) > 1 else 0\n",
    "            frr = 1 - tar\n",
    "            window_metrics = {\n",
    "                'Model': name,\n",
    "                'Window': start,\n",
    "                'Accuracy': accuracy_score(y_true, y_pred),\n",
    "                'Precision': precision_score(y_true, y_pred, average='weighted', zero_division=0),\n",
    "                'Recall': recall_score(y_true, y_pred, average='weighted', zero_division=0),\n",
    "                'F1-Score': f1_score(y_true, y_pred, average='weighted', zero_division=0),\n",
    "                'TPR': tpr,\n",
    "                'FPR': fpr,\n",
    "                'TAR': tar,\n",
    "                'FRR': frr\n",
    "            }\n",
    "            window_results.append(window_metrics)\n",
    "            window_accs.append(window_metrics['Accuracy'])\n",
    "\n",
    "            if is_first_window:\n",
    "                autoencoder.fit(X_window[:int(0.8 * len(X_window))])\n",
    "                is_first_window = False\n",
    "\n",
    "            drift_detected = False\n",
    "            for i in range(len(X_window)):\n",
    "                x = X_window[i]\n",
    "                y_true = y_window[i]\n",
    "                pred = model.predict_one(dict(zip(features, x))) or 0\n",
    "                error = 1.0 if pred != y_true else 0.0\n",
    "                global_idx = start + i\n",
    "                for det_name, det in detectors.items():\n",
    "                    if det_name == 'DDM':\n",
    "                        update = det.add_element(error)\n",
    "                    elif det_name == 'EDDM':\n",
    "                        update = det.add_element(pred, y_true)\n",
    "                    elif det_name == 'PCDM':\n",
    "                        update = det.add_element(x[0])\n",
    "                    elif det_name == 'RBFSVMDriftDetector':\n",
    "                        update = det.add_element(x, y_true)\n",
    "                    else:\n",
    "                        update = det.update(x[0])\n",
    "                    if update:\n",
    "                        key = f'{det_name.lower()}_{features[0]}'\n",
    "                        if key in drift_points[name]:\n",
    "                            drift_points[name][key].append(global_idx)\n",
    "                        drift_detected = True\n",
    "                        adaptation_latencies.append(global_idx)\n",
    "\n",
    "            if adaptive and drift_detected:\n",
    "                model = copy.deepcopy(base_model)\n",
    "                for j in range(len(X_window)):\n",
    "                    sample = dict(zip(features, X_window[j]))\n",
    "                    model.learn_one(sample, y_window[j])\n",
    "                y_pred_post = [model.predict_one(dict(zip(features, x))) or 0 for x in X_window[1:]]\n",
    "                window_metrics['Post-Accuracy'] = accuracy_score(y_true, y_pred_post)\n",
    "\n",
    "            window_results[-1] = window_metrics\n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating {name} at window {start}: {e}\")\n",
    "    return window_results, adaptation_latencies, window_accs\n",
    "\n",
    "# Main evaluation function with DDA and AL\n",
    "def evaluate_models(data_df, data_type, features, attack_type, drift_type, window_size=100, step_size=10):\n",
    "    try:\n",
    "        X = data_df[features].values\n",
    "        y = data_df['label'].values\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        models = {\n",
    "            'Random Forest': RandomForestClassifier(n_estimators=50, max_depth=3, min_samples_split=10, random_state=42),  # Reduced complexity\n",
    "            'SVM': SVC(kernel='rbf', C=0.5, probability=True, random_state=42),\n",
    "            'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "            'XGBoost': XGBClassifier(n_estimators=50, max_depth=2, learning_rate=0.01, reg_lambda=1.0, random_state=42),\n",
    "            'Voting': VotingClassifier(estimators=[\n",
    "                ('rf', RandomForestClassifier(n_estimators=50, max_depth=3, min_samples_split=10, random_state=42)),\n",
    "                ('svm', SVC(kernel='rbf', C=0.5, probability=True, random_state=42)),\n",
    "                ('knn', KNeighborsClassifier(n_neighbors=5))\n",
    "            ], voting='soft'),\n",
    "            'Snapshot RF': SnapshotEnsemble(RandomForestClassifier(n_estimators=50, max_depth=3, min_samples_split=10, random_state=42), n_snapshots=2),\n",
    "            'Hoeffding Tree': HoeffdingTreeClassifier(grace_period=50, delta=0.01),  # Corrected parameter\n",
    "            'HAT': HoeffdingAdaptiveTreeClassifier(grace_period=50, delta=0.01),    # Corrected parameter\n",
    "            'Leveraging Bagging': LeveragingBaggingClassifier(model=HoeffdingTreeClassifier(grace_period=50, delta=0.01), n_models=5),\n",
    "            'Online Boosting': AdaBoostClassifier(model=HoeffdingTreeClassifier(grace_period=50, delta=0.01), n_models=5),\n",
    "            'OKD': OnlineKnowledgeDistillation(\n",
    "                teacher_model=HoeffdingAdaptiveTreeClassifier(grace_period=50, delta=0.01),\n",
    "                student_model=HoeffdingTreeClassifier(grace_period=50, delta=0.01),\n",
    "                alpha=0.5\n",
    "            )\n",
    "        }\n",
    "        if ENSEMBLE_AVAILABLE:\n",
    "            if ENSEMBLE_NAME == 'ARF':\n",
    "                models[ENSEMBLE_NAME] = EnsembleClassifier(n_estimators=5)\n",
    "            else:  # SRP\n",
    "                models[ENSEMBLE_NAME] = EnsembleClassifier(n_models=5)\n",
    "        \n",
    "        results = []\n",
    "        detectors = ['adwin', 'page_hinkley', 'ddm', 'eddm', 'kswin', 'pcdm', 'rbf_svm', 'hddm_w', 'hddm_a', 'autoencoder']\n",
    "        drift_points = {name: {f'{detector}_{feature}': [] for detector in detectors for feature in features} for name in models}\n",
    "        true_drifts = [len(data_df[data_df['label'] == 0]) + 50]  # Drift near attack start\n",
    "        adaptation_latencies = {name: [] for name in models}\n",
    "        output_dir = f'/Users/festusedward-n/Documents/Datasets/{data_type}_{attack_type}_{drift_type}'\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        streaming_models = ['Hoeffding Tree', 'HAT', ENSEMBLE_NAME, 'Leveraging Bagging', 'Online Boosting', 'OKD']\n",
    "        \n",
    "        for name, model in models.items():\n",
    "            print(f\"Training and evaluating {name}...\")\n",
    "            try:\n",
    "                eval_func = evaluate_streaming_model if name in streaming_models else evaluate_batch_model\n",
    "                \n",
    "                # Adaptive run with consensus-based drift\n",
    "                adaptive_results, adaptive_latencies, adaptive_accs = eval_func(name, model, X_scaled, y, features, window_size, step_size, true_drifts, drift_points, output_dir, drift_type, adaptive=True)\n",
    "                adaptation_latencies[name] = adaptive_latencies\n",
    "                \n",
    "                # Static ablation run\n",
    "                static_results, _, static_accs = eval_func(name, model, X_scaled, y, features, window_size, step_size, true_drifts, drift_points, output_dir, drift_type, adaptive=False)\n",
    "                \n",
    "                # Aggregate adaptive results\n",
    "                aggregated = {\n",
    "                    'Model': name,\n",
    "                    'Accuracy_Mean': np.mean([r['Accuracy'] for r in adaptive_results]),\n",
    "                    'Accuracy_CI_Low': bootstrap_ci([r['Accuracy'] for r in adaptive_results])[0],\n",
    "                    'Accuracy_CI_High': bootstrap_ci([r['Accuracy'] for r in adaptive_results])[1],\n",
    "                    'TPR_Mean': np.mean([r['TPR'] for r in adaptive_results]),\n",
    "                    'TPR_CI_Low': bootstrap_ci([r['TPR'] for r in adaptive_results])[0],\n",
    "                    'TPR_CI_High': bootstrap_ci([r['TPR'] for r in adaptive_results])[1],\n",
    "                    'FRR_Mean': np.mean([r['FRR'] for r in adaptive_results]),\n",
    "                    'FRR_CI_Low': bootstrap_ci([r['FRR'] for r in adaptive_results])[0],\n",
    "                    'FRR_CI_High': bootstrap_ci([r['FRR'] for r in adaptive_results])[1],\n",
    "                    'Precision_Mean': np.mean([r['Precision'] for r in adaptive_results]),\n",
    "                    'Recall_Mean': np.mean([r['Recall'] for r in adaptive_results]),\n",
    "                    'F1_Mean': np.mean([r['F1-Score'] for r in adaptive_results])\n",
    "                }\n",
    "                \n",
    "                # t-test vs static\n",
    "                if len(adaptive_accs) == len(static_accs) and adaptive_accs and static_accs:\n",
    "                    t_stat, p_val = ttest_rel(adaptive_accs, static_accs)\n",
    "                    aggregated['Delta_Acc_vs_Static'] = np.mean(adaptive_accs) - np.mean(static_accs)\n",
    "                    aggregated['p_value_vs_Static'] = p_val\n",
    "                else:\n",
    "                    aggregated['Delta_Acc_vs_Static'] = np.nan\n",
    "                    aggregated['p_value_vs_Static'] = np.nan\n",
    "                \n",
    "                # Compute DDA and AL\n",
    "                total_detections = sum(len(v) for v in drift_points[name].values())\n",
    "                correct_detections = sum(len([d for d in detected if any(abs(d - t) < 50 for t in true_drifts)]) for detected in drift_points[name].values())\n",
    "                aggregated['DDA_Mean'] = correct_detections / max(1, total_detections) if total_detections else 0.0\n",
    "                aggregated['AL_Mean'] = np.mean(adaptation_latencies[name]) if adaptation_latencies[name] else float('inf')\n",
    "                \n",
    "                if 'Post-Accuracy' in adaptive_results[0]:\n",
    "                    aggregated['Post_Accuracy_Mean'] = np.mean([r['Post-Accuracy'] for r in adaptive_results])\n",
    "                \n",
    "                if name in ['Random Forest', 'SVM', 'KNN', 'XGBoost', 'Voting', 'Snapshot RF']:\n",
    "                    roc_vals = [r['ROC-AUC'] for r in adaptive_results if 'ROC-AUC' in r and not np.isnan(r['ROC-AUC'])]\n",
    "                    aggregated['ROC_AUC_Mean'] = np.mean(roc_vals)\n",
    "                \n",
    "                results.append(aggregated)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to evaluate {name}: {e}\")\n",
    "        \n",
    "        results_df = pd.DataFrame(results)\n",
    "        output_file = f'{output_dir}/results.csv'\n",
    "        results_df.to_csv(output_file, index=False)\n",
    "        \n",
    "        print(f\"\\nResults for {data_type}_{attack_type}_{drift_type}:\")\n",
    "        print(results_df[['Model', 'Accuracy_Mean', 'TPR_Mean', 'FRR_Mean', 'DDA_Mean', 'AL_Mean', 'Delta_Acc_vs_Static', 'p_value_vs_Static']])\n",
    "        print(\"Drift Points summary:\", {k: len(v) for k, v in drift_points.items() if v})\n",
    "        \n",
    "        # Plotting (simplified)\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.savefig(f'{output_dir}/f1.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        return results_df, drift_points\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating {data_type} dataset: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Load and preprocess data\n",
    "def load_data(data_file, data_type):\n",
    "    try:\n",
    "        df = pd.read_csv(data_file)\n",
    "        print(f\"Initial {data_type} Rows: {len(df)}\")\n",
    "        if data_type == 'keystroke':\n",
    "            features = ['dwell_time', 'flight_time', 'up_down_time', 'session_duration', 'rhythm']\n",
    "        else:  # mouse\n",
    "            features = ['speed', 'distance']\n",
    "            if 'delta' in df.columns:\n",
    "                try:\n",
    "                    df['delta_x'] = df['delta'].apply(lambda x: float(x.split(',')[0].strip('() ')) if isinstance(x, str) else x[0] if isinstance(x, (list, tuple)) else np.nan)\n",
    "                    df['delta_y'] = df['delta'].apply(lambda x: float(x.split(',')[1].strip('() ')) if isinstance(x, str) else x[1] if isinstance(x, (list, tuple)) else np.nan)\n",
    "                    features += ['delta_x', 'delta_y']\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Failed to parse 'delta' column in {data_type} dataset. Error: {e}\")\n",
    "                    df = df.drop(columns=['delta'])\n",
    "        for feature in features:\n",
    "            if feature not in df.columns:\n",
    "                raise ValueError(f\"Feature '{feature}' not found in {data_type} dataset\")\n",
    "        df = df.dropna(subset=features)\n",
    "        print(f\"{data_type} Rows after NaN drop: {len(df)}\")\n",
    "        df['label'] = 0  # Benign\n",
    "        return df, features\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {data_type} dataset: {e}. Using synthetic data.\")\n",
    "        return generate_synthetic_data(data_type)\n",
    "\n",
    "# Synthetic data generator\n",
    "def generate_synthetic_data(data_type, n_samples=1000):\n",
    "    np.random.seed(42)\n",
    "    if data_type == 'keystroke':\n",
    "        df = pd.DataFrame({\n",
    "            'dwell_time': np.random.normal(100, 20, n_samples),\n",
    "            'flight_time': np.random.normal(150, 30, n_samples),\n",
    "            'up_down_time': np.random.normal(120, 25, n_samples),\n",
    "            'session_duration': np.random.normal(500, 100, n_samples),\n",
    "            'rhythm': np.random.normal(0.8, 0.1, n_samples),\n",
    "            'label': np.random.choice([0, 1], n_samples, p=[0.8, 0.2])  # 80% benign\n",
    "        })\n",
    "        features = ['dwell_time', 'flight_time', 'up_down_time', 'session_duration', 'rhythm']\n",
    "    else:  # mouse\n",
    "        times = np.cumsum(np.random.exponential(0.1, n_samples))\n",
    "        x = np.cumsum(np.random.normal(0, 10, n_samples))\n",
    "        y = np.cumsum(np.random.normal(0, 10, n_samples))\n",
    "        delta_x = np.diff(x, prepend=x[0])\n",
    "        delta_y = np.diff(y, prepend=y[0])\n",
    "        dt = np.diff(times, prepend=times[0])\n",
    "        speed = np.sqrt(delta_x**2 + delta_y**2) / (dt + 1e-6)\n",
    "        distance = np.sqrt(delta_x**2 + delta_y**2)\n",
    "        df = pd.DataFrame({\n",
    "            'speed': speed,\n",
    "            'distance': distance,\n",
    "            'delta_x': delta_x,\n",
    "            'delta_y': delta_y,\n",
    "            'label': np.random.choice([0, 1], n_samples, p=[0.8, 0.2])\n",
    "        })\n",
    "        features = ['speed', 'distance', 'delta_x', 'delta_y']\n",
    "    return df, features\n",
    "\n",
    "# Combine benign and attack data\n",
    "def create_combined_dataset(benign_df, data_type, attack_type, drift_type, n_attack=200, use_generator=False):\n",
    "    attack_df = simulate_attacks(benign_df, data_type, attack_type, drift_type, n_attack, use_generator)\n",
    "    combined_df = pd.concat([benign_df, attack_df], ignore_index=True)\n",
    "    output_dir = '/Users/festusedward-n/Documents/Datasets'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_file = f'{output_dir}/{data_type}_{attack_type}_{drift_type}_data.csv'\n",
    "    combined_df.to_csv(output_file, index=False)\n",
    "    return combined_df\n",
    "\n",
    "# Tune detector based on drift type\n",
    "def get_tuned_detector(detector_class, drift_type):\n",
    "    if drift_type in ['gradual', 'incremental', 'recurring']:\n",
    "        if detector_class == ADWIN:\n",
    "            return ADWIN(delta=0.0001)\n",
    "        elif detector_class == PageHinkley:\n",
    "            return PageHinkley(threshold=10)\n",
    "        elif detector_class == KSWIN:\n",
    "            return KSWIN(alpha=0.005)\n",
    "        elif detector_class == PCDM:\n",
    "            return PCDM(alpha=0.005)\n",
    "        elif detector_class == RBFSVMDriftDetector:\n",
    "            return RBFSVMDriftDetector(threshold=0.05)\n",
    "        elif detector_class == HDDM_W:\n",
    "            return HDDM_W(delta=0.0001)\n",
    "        elif detector_class == HDDM_A:\n",
    "            return HDDM_A(delta=0.0001)\n",
    "        elif detector_class == DDM:\n",
    "            return DDM(drift_level=2.0)\n",
    "        elif detector_class == EDDM:\n",
    "            return EDDM(drift_level=0.8)\n",
    "    else:  # Abrupt\n",
    "        if detector_class == ADWIN:\n",
    "            return ADWIN(delta=0.001)\n",
    "        return detector_class()\n",
    "\n",
    "# Main execution\n",
    "if __name__ == '__main__':\n",
    "    attack_types = [\n",
    "        ('session_hijacking', 'abrupt'),\n",
    "        ('mitm', 'recurring'),\n",
    "        ('card_skimming', 'abrupt'),\n",
    "        ('phishing', 'gradual'),\n",
    "        ('identity_theft', 'incremental')\n",
    "    ]\n",
    "    data_types = ['keystroke', 'mouse']\n",
    "    datasets = {\n",
    "        'keystroke': '/Users/festusedward-n/Documents/Datasets/imputed_keystroke_data.csv',\n",
    "        'mouse': '/Users/festusedward-n/Documents/Datasets/mouse_modified_trimmed_clean_imputed.csv'\n",
    "    }\n",
    "    for data_type, data_file in datasets.items():\n",
    "        benign_df, features = load_data(data_file, data_type)\n",
    "        if benign_df is None:\n",
    "            continue\n",
    "        for attack_type, drift_type in attack_types:\n",
    "            print(f\"\\nCreating dataset for {data_type}_{attack_type}_{drift_type}\")\n",
    "            combined_df = create_combined_dataset(benign_df, data_type, attack_type, drift_type, use_generator=True)\n",
    "            print(f\"Evaluating models for {data_type}_{attack_type}_{drift_type}\")\n",
    "            results_df, drift_points = evaluate_models(combined_df, data_type, features, attack_type, drift_type, window_size=100, step_size=10)\n",
    "            if results_df is not None:\n",
    "                print(f\"\\nResults for {data_type}_{attack_type}_{drift_type}:\")\n",
    "                print(results_df[['Model', 'Accuracy_Mean', 'TPR_Mean', 'FRR_Mean', 'DDA_Mean', 'AL_Mean', 'Delta_Acc_vs_Static', 'p_value_vs_Static']])\n",
    "                print(\"Drift Points summary:\", {k: len(v) for k, v in drift_points.items() if v})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ececc54e-fff3-42d1-8f87-a53539ac7f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch_env_310)",
   "language": "python",
   "name": "pytorch_env_310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
